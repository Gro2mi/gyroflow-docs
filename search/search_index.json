{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to the Gyroflow Docs! Return to gyroflow.xyz Here you can find information about setup and configuration of the Gyroflow stabilization software. What is Gyroflow? In order to achieve smooth, cinematic footage, video stabilization is often essential. For cinema cameras, this is often achieved using motorized gimbals or other bulky camera stabilizers. Phone cameras and compact action cameras on the other hand use Electronic Image Stabilization (EIS) applied in real-time based on gyro sensor data. Finally, video editing packages can often stabilize video based on estimated camera motion, which may be unreliable. This is where Gyroflow comes into play. Gyroflow is a post-processing video stabilization software based on logged motion data. With the help of precise lens calibrations, rolling shutter correction, and tweakable stabilization algorithms (including horizon levelling), Gyroflow can produce gimbal-like stabilization with no or minimal weight penalty. It also works regardless of lighting conditions or moving subjects. This is especially suited for aerial videography, where the beta version has been extensively evaluated for large and small productions alike. With many cameras from GoPro, Sony, insta360 etc. supporting built-in motion data recording, additional hardware might not even be required. You can even use a GoPro as a logger for a cinema camera. Gyroflow is cross-platform (even supports Apple Silicon), and uses hardware acceleration for blazingly fast processing combined with a modern multilingual user interface.","title":"Home"},{"location":"#welcome-to-the-gyroflow-docs","text":"Return to gyroflow.xyz Here you can find information about setup and configuration of the Gyroflow stabilization software.","title":"Welcome to the Gyroflow Docs!"},{"location":"#what-is-gyroflow","text":"In order to achieve smooth, cinematic footage, video stabilization is often essential. For cinema cameras, this is often achieved using motorized gimbals or other bulky camera stabilizers. Phone cameras and compact action cameras on the other hand use Electronic Image Stabilization (EIS) applied in real-time based on gyro sensor data. Finally, video editing packages can often stabilize video based on estimated camera motion, which may be unreliable. This is where Gyroflow comes into play. Gyroflow is a post-processing video stabilization software based on logged motion data. With the help of precise lens calibrations, rolling shutter correction, and tweakable stabilization algorithms (including horizon levelling), Gyroflow can produce gimbal-like stabilization with no or minimal weight penalty. It also works regardless of lighting conditions or moving subjects. This is especially suited for aerial videography, where the beta version has been extensively evaluated for large and small productions alike. With many cameras from GoPro, Sony, insta360 etc. supporting built-in motion data recording, additional hardware might not even be required. You can even use a GoPro as a logger for a cinema camera. Gyroflow is cross-platform (even supports Apple Silicon), and uses hardware acceleration for blazingly fast processing combined with a modern multilingual user interface.","title":"What is Gyroflow?"},{"location":"cams/general/","text":"General recording tips Use the settings that give the widest possible field of view. This results in more data to work with. For a lot of cameras, this is using the 4:3 aspect ratio if available. If using the main flight controller on a drone for logging, the camera should be rigidly mounted to the drone. If using a secondary logger on the camera or internal camera logging, some soft mounting is preferred when used in a high-vibration environment (drones). Internal stabilization should be disabled. Furthermore, trying to stabilize footage from a camera with IBIS may result in wobble due to the sensor shifting around. In filmmaking, the 180 degree shutter rule is commonly used (shutter speed half of framerate). Depending on your use case and amount of shake, applying Gyroflow stabilization may result in undesired motion blur artifacts. A 90 degree shutter is typically a good compromise between artifacts and pleasing motion blur, and is thus a good starting point. Even higher shutter speeds can make the footage look less \"cinematic\" due to the lack of motion blur.","title":"General"},{"location":"cams/general/#general-recording-tips","text":"Use the settings that give the widest possible field of view. This results in more data to work with. For a lot of cameras, this is using the 4:3 aspect ratio if available. If using the main flight controller on a drone for logging, the camera should be rigidly mounted to the drone. If using a secondary logger on the camera or internal camera logging, some soft mounting is preferred when used in a high-vibration environment (drones). Internal stabilization should be disabled. Furthermore, trying to stabilize footage from a camera with IBIS may result in wobble due to the sensor shifting around. In filmmaking, the 180 degree shutter rule is commonly used (shutter speed half of framerate). Depending on your use case and amount of shake, applying Gyroflow stabilization may result in undesired motion blur artifacts. A 90 degree shutter is typically a good compromise between artifacts and pleasing motion blur, and is thus a good starting point. Even higher shutter speeds can make the footage look less \"cinematic\" due to the lack of motion blur.","title":"General recording tips"},{"location":"cams/gopro/","text":"From the GoPro Hero 5 and onwards, the GPMF metadata has contained useful motion data supported by Gyroflow. Unfortunately not all cameras work equally well: General All GoPros use 4:3 sensors and allow for different field of views. For Gyroflow stabilization, the best resolutions are 4:3 resolutions with the wide field of view. This gives Gyroflow the most image data to work with. Hero 8/9/10 These cameras all contain pre-computed camera orientations for every single frame, meaning the synchronisation step can be skipped when using the None integration method. Footage from these cameras are essentially \"plug and play\" when it comes to Gyroflow stabilization, since Gyroflow contains built-in lens profiles for all these cameras. Furthermore, since these cameras do internal rolling shutter processing, additional rolling shutter correction is not required. Finally, the GPMF metadata also contains transformed orientation information when hypersmooth is enabled, meaning further stabilization of hypersmoothed footage in Gyroflow is possible. Hero 7 The Hero 7 is a bit of an outlier. For drone footage, the gyro data from the Hero 7 have been found to be lackluster to say the least. High amounts of noise and aliasing means Gyroflow stabilization using the internal data is likely to give bad results. For this reason, the Hero 7 is not recommended for cinematic FPV footage. One workaround is to use external gyro logging, for instance using the drone blackbox. Another workaround is the use of vibration-dampening mount, which can be a hassle compared to other GoPros. Some users have reported that using intense low pass filtering of the gyro data (e.g. cutoff of 4 Hz or less) can yield acceptable results for some drone footage. This cannot correct for e.g. higher frequency propwash oscillations or vibrations, but can smooth out the general movement. The Hero 7 doesn't compute per-frame orientations, meaning synchronization is required. For handheld footage, the mentioned noise issues shouldn't be a problem. Furthermore, footage from the Hero 7 with Hypersmooth enabled does not work with Gyroflow. Hero 6 The Hero 6 contains gyroscope and accelerometer data, and can thus be used with Gyroflow out of the box. Due to the lack of per-frame orientations, the synchronization step is still required. The Hero 6 doesn't exhibit the noise issues of the Hero 7, and works well for drone footage. Compared to Hero 8/9/10, no internal rolling shutter processing is performed, meaning fast motion can cause warping, if no rolling shutter correction is applied in Gyroflow. Hero 5/Session 5 The Hero 5 exhibits similar vibration-induced noise problems to the Hero 7, and is thus not recommended for drone footage out of the box. Once again, users have reported achieving acceptable stabilization using intense low pass filtering, so if you already have this camera, that's worth a try. Just like the Hero 7, handheld footage doesn't yield any major problems.","title":"GoPro"},{"location":"cams/gopro/#general","text":"All GoPros use 4:3 sensors and allow for different field of views. For Gyroflow stabilization, the best resolutions are 4:3 resolutions with the wide field of view. This gives Gyroflow the most image data to work with.","title":"General"},{"location":"cams/gopro/#hero-8910","text":"These cameras all contain pre-computed camera orientations for every single frame, meaning the synchronisation step can be skipped when using the None integration method. Footage from these cameras are essentially \"plug and play\" when it comes to Gyroflow stabilization, since Gyroflow contains built-in lens profiles for all these cameras. Furthermore, since these cameras do internal rolling shutter processing, additional rolling shutter correction is not required. Finally, the GPMF metadata also contains transformed orientation information when hypersmooth is enabled, meaning further stabilization of hypersmoothed footage in Gyroflow is possible.","title":"Hero 8/9/10"},{"location":"cams/gopro/#hero-7","text":"The Hero 7 is a bit of an outlier. For drone footage, the gyro data from the Hero 7 have been found to be lackluster to say the least. High amounts of noise and aliasing means Gyroflow stabilization using the internal data is likely to give bad results. For this reason, the Hero 7 is not recommended for cinematic FPV footage. One workaround is to use external gyro logging, for instance using the drone blackbox. Another workaround is the use of vibration-dampening mount, which can be a hassle compared to other GoPros. Some users have reported that using intense low pass filtering of the gyro data (e.g. cutoff of 4 Hz or less) can yield acceptable results for some drone footage. This cannot correct for e.g. higher frequency propwash oscillations or vibrations, but can smooth out the general movement. The Hero 7 doesn't compute per-frame orientations, meaning synchronization is required. For handheld footage, the mentioned noise issues shouldn't be a problem. Furthermore, footage from the Hero 7 with Hypersmooth enabled does not work with Gyroflow.","title":"Hero 7"},{"location":"cams/gopro/#hero-6","text":"The Hero 6 contains gyroscope and accelerometer data, and can thus be used with Gyroflow out of the box. Due to the lack of per-frame orientations, the synchronization step is still required. The Hero 6 doesn't exhibit the noise issues of the Hero 7, and works well for drone footage. Compared to Hero 8/9/10, no internal rolling shutter processing is performed, meaning fast motion can cause warping, if no rolling shutter correction is applied in Gyroflow.","title":"Hero 6"},{"location":"cams/gopro/#hero-5session-5","text":"The Hero 5 exhibits similar vibration-induced noise problems to the Hero 7, and is thus not recommended for drone footage out of the box. Once again, users have reported achieving acceptable stabilization using intense low pass filtering, so if you already have this camera, that's worth a try. Just like the Hero 7, handheld footage doesn't yield any major problems.","title":"Hero 5/Session 5"},{"location":"cams/insta360/","text":"Action cameras from Insta360 (OneR, SMO 4k, Go, GO2) support gyro logging for use with the Flowstate stabilization option. This metadata also works with Gyroflow. Once again, try recording at the widest possible field of view. e.g. the Pro Video on the Go 2 saves the full sensor frame.","title":"Insta360"},{"location":"cams/runcam/","text":"The gyros in both the runcam 5 Orange and gocam PM GR can be sensitive to strong vibrations. You should therefore not rigidly mount it to a source of vibrations (e.g. Drone), but instead use either a TPU mount or similar. The runcam 5 seems to tolerate vibrations decently well, so standard TPU or foam mounts should suffice. From limited testing, the gocam may be more sensitive to motor noise, so see if you can find or 3D print something for better vibration isolation. Runcam 5 Orange Surprise! All along the Runcam 5 Orange had an IMU hidden inside. This was of course previously used for the EIS, but with the newest versions of the firmware, the gyro and accelerometer data can be logged to a CSV file along with the video for post stabilization with Gyroflow. Find the firmware here: https://www.runcam.com/download/runcam5or The following have been found to be decent settings for the Runcam 5 Orange, with * indicating it's important for Gyroflow stabilization. Video quality: High Resolution*: Either 4K@30FPS(XV) or 1440p@60fps. The XV resolution is actually the full 4:3 sensor stretched to a 16:9 image. So this gives the highest resolution and FOV. Note that the stretching looks bad, so if used without additional processing, linearly squeeze the width to 75% in the video editor to get a 4:3 image. The 1440p option is natively 4:3, so if you want 60fps use this one. You can also use one of the 16:9 resolutions, but this significantly reduces the available FOV for stabilization. Volume: You decide Shutter*: Try to get a 90 to 180 degree shutter. So from 1/60 to 1/120 for 30fps and about 1/120 to 1/240 for 60 fps footage. (ND filter may be needed) ISO: As low as possible. There seems to be some auto gain regardless of settings. Color style: Normal (Flat squeezes the range and doesn\u2019t actually provide more dynamic range) Distortion correction*: Disabled Electronic Image Stabilization*: Disabled General settings (there were just found to work decently decently well, but do some testing yourself) Saturation: Medium Exposure compensation: 0 Contrast: Low Sharpness: Low Metering: Average White balance: Sunny (change depending on scenario, don\u2019t use auto) Low light enhancement: you decide. File processing Note This was required for the initial gyro logging firmware, and may not be applicable with the latest firmware. With the initial gyro logging firmware for the Runcam 5, it had an issue with occasionally generating a duplicate frame, which leads to jitter in the stabilized output. This could be fixed by the time you read this, but otherwise there\u2019s a way to solve it. FFmpeg has a command which can detect and remove duplicate frames. I will assume you already have FFmpeg available in the command line, if not, install it from ffmpeg.org . Duplicate frame detection: Run: ffmpeg -i INPUTVIDEOFILE.mp4 -vf mpdecimate=hi=64:lo=32:frac=0.1 -loglevel debug -f null - After a few seconds, you'll see this: Typically there\u2019s a duplicate frame every 30 seconds. If the input and output frames are the same, then it isn\u2019t an issue. If they are different, we need to get rid of the duplicate frames using the following command: ffmpeg -i RC_0001_210724181232.MP4 -vf mpdecimate=hi=64:lo=32:frac=0.1,setpts=N/FRAME_RATE/TB -c:v libx264 -crf 18 RC_0001_filtered.mp4 (replace with your filenames). Lower value for -crf means less compression If using an nvidia GPU (faster processing): ffmpeg -i RC_0001_210724181232.MP4 -vf mpdecimate=hi=64:lo=32:frac=0.1,setpts=N/FRAME_RATE/TB -c:v h264_nvenc -b:v 50M RC_0001_filtered.MP4 The 50M means encoding at 50 Mbps, change if needed. Replacing h264_nvenc with h264_amf should work for AMD systems In Gyroflow If using 4K XV, use the preset: RunCam/Runcam_5_Orange_4K_30FPS_XV_16by9_stretched.json If using 1440p 60fps use: RunCam/Runcam_5_Orange_1440p_4by3.json Low pass filter at about 60 Hz should be fine Note : Gyroflow v1.0.0-rc1 does not yet support the 4K XV option right away (will be added shortly). Use adjust parameters and change the first Pixel focal length value from 1503.650975788249 to 2004.868 : GOCam PM GR Depending on your setup, you might need to softmount this cam, since the the gyro can be sensitive to motor noise vibrations. Settings First of all, download the latest firmware. With the initial firmware, the only 4:3 resolution is 1440p 60fps. If you want the full sensor use that. Otherwise use the 4K resolution (works fine if you end up cropping to a cinematic aspect ratio) In Gyroflow Use either the RunCam/Runcam_Iflight_Gocam_1440p_4by3.json preset or the RunCam/Runcam_Iflight_Gocam_PMGR_4K_16by9.json preset depending on setting A 50 Hz low pass filter setting is a good starting point.","title":"Runcam"},{"location":"cams/runcam/#runcam-5-orange","text":"Surprise! All along the Runcam 5 Orange had an IMU hidden inside. This was of course previously used for the EIS, but with the newest versions of the firmware, the gyro and accelerometer data can be logged to a CSV file along with the video for post stabilization with Gyroflow. Find the firmware here: https://www.runcam.com/download/runcam5or The following have been found to be decent settings for the Runcam 5 Orange, with * indicating it's important for Gyroflow stabilization. Video quality: High Resolution*: Either 4K@30FPS(XV) or 1440p@60fps. The XV resolution is actually the full 4:3 sensor stretched to a 16:9 image. So this gives the highest resolution and FOV. Note that the stretching looks bad, so if used without additional processing, linearly squeeze the width to 75% in the video editor to get a 4:3 image. The 1440p option is natively 4:3, so if you want 60fps use this one. You can also use one of the 16:9 resolutions, but this significantly reduces the available FOV for stabilization. Volume: You decide Shutter*: Try to get a 90 to 180 degree shutter. So from 1/60 to 1/120 for 30fps and about 1/120 to 1/240 for 60 fps footage. (ND filter may be needed) ISO: As low as possible. There seems to be some auto gain regardless of settings. Color style: Normal (Flat squeezes the range and doesn\u2019t actually provide more dynamic range) Distortion correction*: Disabled Electronic Image Stabilization*: Disabled General settings (there were just found to work decently decently well, but do some testing yourself) Saturation: Medium Exposure compensation: 0 Contrast: Low Sharpness: Low Metering: Average White balance: Sunny (change depending on scenario, don\u2019t use auto) Low light enhancement: you decide.","title":"Runcam 5 Orange"},{"location":"cams/runcam/#file-processing","text":"Note This was required for the initial gyro logging firmware, and may not be applicable with the latest firmware. With the initial gyro logging firmware for the Runcam 5, it had an issue with occasionally generating a duplicate frame, which leads to jitter in the stabilized output. This could be fixed by the time you read this, but otherwise there\u2019s a way to solve it. FFmpeg has a command which can detect and remove duplicate frames. I will assume you already have FFmpeg available in the command line, if not, install it from ffmpeg.org . Duplicate frame detection: Run: ffmpeg -i INPUTVIDEOFILE.mp4 -vf mpdecimate=hi=64:lo=32:frac=0.1 -loglevel debug -f null - After a few seconds, you'll see this: Typically there\u2019s a duplicate frame every 30 seconds. If the input and output frames are the same, then it isn\u2019t an issue. If they are different, we need to get rid of the duplicate frames using the following command: ffmpeg -i RC_0001_210724181232.MP4 -vf mpdecimate=hi=64:lo=32:frac=0.1,setpts=N/FRAME_RATE/TB -c:v libx264 -crf 18 RC_0001_filtered.mp4 (replace with your filenames). Lower value for -crf means less compression If using an nvidia GPU (faster processing): ffmpeg -i RC_0001_210724181232.MP4 -vf mpdecimate=hi=64:lo=32:frac=0.1,setpts=N/FRAME_RATE/TB -c:v h264_nvenc -b:v 50M RC_0001_filtered.MP4 The 50M means encoding at 50 Mbps, change if needed. Replacing h264_nvenc with h264_amf should work for AMD systems In Gyroflow If using 4K XV, use the preset: RunCam/Runcam_5_Orange_4K_30FPS_XV_16by9_stretched.json If using 1440p 60fps use: RunCam/Runcam_5_Orange_1440p_4by3.json Low pass filter at about 60 Hz should be fine Note : Gyroflow v1.0.0-rc1 does not yet support the 4K XV option right away (will be added shortly). Use adjust parameters and change the first Pixel focal length value from 1503.650975788249 to 2004.868 :","title":"File processing"},{"location":"cams/runcam/#gocam-pm-gr","text":"Depending on your setup, you might need to softmount this cam, since the the gyro can be sensitive to motor noise vibrations.","title":"GOCam PM GR"},{"location":"cams/runcam/#settings","text":"First of all, download the latest firmware. With the initial firmware, the only 4:3 resolution is 1440p 60fps. If you want the full sensor use that. Otherwise use the 4K resolution (works fine if you end up cropping to a cinematic aspect ratio)","title":"Settings"},{"location":"cams/runcam/#in-gyroflow","text":"Use either the RunCam/Runcam_Iflight_Gocam_1440p_4by3.json preset or the RunCam/Runcam_Iflight_Gocam_PMGR_4K_16by9.json preset depending on setting A 50 Hz low pass filter setting is a good starting point.","title":"In Gyroflow"},{"location":"cams/sony/","text":"The following cameras are capable of native gyro data logging: a1, a6600, a7c, a7r IV, a7 IV, a7s III, a9 II, FX3, FX6, RX0 II, RX100 VII, ZV1, ZV-E10 This data is designed for use with Sony's Catalyst Browse stabilization which cannot stabilize footage shot with third-party lenses. Gyroflow supports reading this metadata natively, thus giving access to more smoothing algorithms and support for third-party lenses.","title":"Sony"},{"location":"contrib/documentation/","text":"Help with documentation This site uses MkDocs and Material for MkDocs and is formatted with Markdown. Here's how to serve a local version for editing purposes Install MkDocs and Material for MkDocs: pip install mkdocs-material Clone the repo: git clone https://github.com/gyroflow/gyroflow-docs.git Run local server: mkdocs serve Alternatively each page has an edit button which directly opens the GitHub online editor. In general, create GitHub pull request to merge the edits. MkDocs/Markdown examples Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. This is a warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Image with lightbox: Image title This is some text with a footnote 1 . Here's a LaTeX math block rendered using MathJax $$ c = \\sqrt{a^2 + b^2} $$ Here's a Python code block with line numbers 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Generate 24 different (right handed) orientations using cross products def generate_rotmats (): basis = [[ 1 , 0 , 0 ], [ 0 , 1 , 0 ], [ 0 , 0 , 1 ], [ - 1 , 0 , 0 ], [ 0 , - 1 , 0 ], [ 0 , 0 , - 1 ]] # Six different unit vectors basis = [ np . array ( v ) for v in basis ] ORIENTATIONS = [] for i in range ( len ( basis )): for j in range ( len ( basis )): if i != j and ( i + 3 ) % 6 != j : ivec = basis [ i ] jvec = basis [ j ] kvec = np . cross ( ivec , jvec ) mat = np . vstack ([ ivec , jvec , kvec ]) . transpose () ORIENTATIONS . append ( mat ) Content of the footnote \u21a9","title":"Documentation"},{"location":"contrib/documentation/#help-with-documentation","text":"This site uses MkDocs and Material for MkDocs and is formatted with Markdown. Here's how to serve a local version for editing purposes Install MkDocs and Material for MkDocs: pip install mkdocs-material Clone the repo: git clone https://github.com/gyroflow/gyroflow-docs.git Run local server: mkdocs serve Alternatively each page has an edit button which directly opens the GitHub online editor. In general, create GitHub pull request to merge the edits.","title":"Help with documentation"},{"location":"contrib/documentation/#mkdocsmarkdown-examples","text":"Note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. This is a warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Image with lightbox: Image title This is some text with a footnote 1 . Here's a LaTeX math block rendered using MathJax $$ c = \\sqrt{a^2 + b^2} $$ Here's a Python code block with line numbers 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # Generate 24 different (right handed) orientations using cross products def generate_rotmats (): basis = [[ 1 , 0 , 0 ], [ 0 , 1 , 0 ], [ 0 , 0 , 1 ], [ - 1 , 0 , 0 ], [ 0 , - 1 , 0 ], [ 0 , 0 , - 1 ]] # Six different unit vectors basis = [ np . array ( v ) for v in basis ] ORIENTATIONS = [] for i in range ( len ( basis )): for j in range ( len ( basis )): if i != j and ( i + 3 ) % 6 != j : ivec = basis [ i ] jvec = basis [ j ] kvec = np . cross ( ivec , jvec ) mat = np . vstack ([ ivec , jvec , kvec ]) . transpose () ORIENTATIONS . append ( mat ) Content of the footnote \u21a9","title":"MkDocs/Markdown examples"},{"location":"contrib/gyroflow/","text":"For contributing to the main Gyroflow program, refer to the Github repository . Feature requests can be submitted by opening issues, and new features can be added through pull requests. Another way of contributing to the project is by helping translate the program to your language. This is done through crowdin : https://crowdin.com/project/gyroflow . Currently Gyroflow is available in: English (base language) Polish (by AdrianEddy ) German (by Grommi and Nicecrash ) Danish (by ElvinC ) Norwegian (by MiniGod and alexagv ) Chinese Simplified (by DusKing1 ) Chinese Traditional (by DusKing1 ) Furthermore, you can contribute to the Gyroflow project by creating and submitting new lens profiles. This allows future users with the same hardware to start using the software right away.","title":"Gyroflow"},{"location":"contrib/support/","text":"The Gyroflow project was initially a Python program started by Elvin in 2020. Elvin is currently one of the developers working on software and hardware development: Support Elvin via Patreon Version 1.0 and onwards was made possible by AdrianEddy, who worked overtime on adapting the previous Python codebase to high-performance cross-platform Rust code with a modern UI, and implemented new advanced features like rolling shutter correction. You can find AdrianEddy on Github: AdrianEddy Other contributors Other amazing contributors have helped during the development by discussing, testing, and implementing new ideas for video stabilization, both for the previous Python version and the current software. Some of these people are: Aphobius - Author of velocity dampened smoothing algorithm Marc Roeschlin - Author of adaptive zoom algorithm alexagv - Investigated advanced rendering options for the Python version nivim - Work on insta360 support for the Python version MiniGod - Investigated sync-less GoPro stabilization Gro2mi - Work on automatic lens calibration and sync for the Python version DusKing1 - Hardware development and translations for Gyroflow NiceCrash - Started a community around FPV video stabilization and has been an alpha/beta tester with involvement from the very beginning of the project Finally, a huge thanks goes out to everyone who provided sample footage during the development. This has made it possible to natively support a wide range of cameras and gyro sources. Fun fact: Elvin did not own a suitable camera for testing in the initial months of the project, so Gyroflow would literally not have been made without everyone's willingness to help.","title":"Support Gyroflow / Contributors list"},{"location":"contrib/support/#other-contributors","text":"Other amazing contributors have helped during the development by discussing, testing, and implementing new ideas for video stabilization, both for the previous Python version and the current software. Some of these people are: Aphobius - Author of velocity dampened smoothing algorithm Marc Roeschlin - Author of adaptive zoom algorithm alexagv - Investigated advanced rendering options for the Python version nivim - Work on insta360 support for the Python version MiniGod - Investigated sync-less GoPro stabilization Gro2mi - Work on automatic lens calibration and sync for the Python version DusKing1 - Hardware development and translations for Gyroflow NiceCrash - Started a community around FPV video stabilization and has been an alpha/beta tester with involvement from the very beginning of the project Finally, a huge thanks goes out to everyone who provided sample footage during the development. This has made it possible to natively support a wide range of cameras and gyro sources. Fun fact: Elvin did not own a suitable camera for testing in the initial months of the project, so Gyroflow would literally not have been made without everyone's willingness to help.","title":"Other contributors"},{"location":"guide/calibration/","text":"The purpose of the camera calibration process is to accurately determine the intrinsic parameters of a camera system. This consists of the focal length, lens distortions, and other misalignments during the imaging process. These parameters can be found through lens calibration, which consists of imaging a known pattern, and analyzing the resulting footage. The Gyroflow lens calibrator looks like this: Video guide (outdated) The calibration process between 0.3.0-beta and 1.0 is overall pretty similar, with the previously created presets being compatible with the new version of the software. Getting calibration footage Display the calibration pattern on a flat computer monitor, preferably in full screen (available from the lens calibrator utility). You can also print it out if you prefer. In general, larger calibration patterns are preferred since focus will be closer to the focus during actual use. A bright screen with a slightly darkened room works well. Select the desired camera settings to calibrate for. Most importantly the field of view/focal length and aspect ratio, if applicable. Framerate and resolution doesn't matter, only if the resolution changes the field of view. Too low shutter speed may also cause undesirable motion blur, but it's usually fine. Record the pattern while slowly moving around to different angles and distances in one clip. 60 seconds is typically more than enough. Try to avoid motion blur by holding the camera still in each angles and with slow movements, and make sure the full chessboard is in view. The following angles are recommended for getting distortion information from the full frame: Chessboard filling whole frame Chessboard seen from distance. Chessboard seen at an angle. Each edge of video frame aligned with edge of chessboard. Corner of chessboard aligned with corner of video. The default (14x8) calibration pattern is also available below: Creating camera preset Start the Gyroflow tool and click create new under the lens profile tab. Open the previously recorded calibration video file. Either begin auto calibration or manually add frames using add calibration point from the timeline context menu. After either the automatic or manual calibration process, check the reprojection error . This value describes the overall error between the preset and actual lens distortion based on the expected features of the calibration pattern. After all required frames are added and processed, the straight lines should be straight in the undistorted video. Reprojection error should typically be under 5 (pixels) with excellent calibrations giving values below 1. Fill in the preset information and export the lens profile. Try to add all relevant information about the camera/lens combination including field of view setting and lens focal length if applicable. If a successful calibration was achieved with a low reprojection error and no obvious artefacts, the profile can be submitted with the Upload lens profile to the database checkbox. You're now ready to use the new lens preset. These are stored as .json files. Additional calibration options The lens calibrator contains additional options. Default output size Radial lens undistortion typically results in the image being stretched more in the horizontal axis (use the FOV slider to see this). For instance, undistorted 4:3 GoPro video: Notice that the area of the valid rectangle is close to a 16:9 aspect ratio as opposed to 4:3. In these cases, the default output size can be modified to a 16:9 one. For cameras with minimal fisheye distortion, or even with pincushion distortion, the resulting valid aspect ratio is close to the original one. For these cameras, just use the input resolution for the default output size. Sharpness limit Sets the minimum required sharpness for the calibration pattern. If the pattern failed to detect due to focus or blurriness, try increasing this limit.","title":"Camera Calibration"},{"location":"guide/calibration/#video-guide-outdated","text":"The calibration process between 0.3.0-beta and 1.0 is overall pretty similar, with the previously created presets being compatible with the new version of the software.","title":"Video guide (outdated)"},{"location":"guide/calibration/#getting-calibration-footage","text":"Display the calibration pattern on a flat computer monitor, preferably in full screen (available from the lens calibrator utility). You can also print it out if you prefer. In general, larger calibration patterns are preferred since focus will be closer to the focus during actual use. A bright screen with a slightly darkened room works well. Select the desired camera settings to calibrate for. Most importantly the field of view/focal length and aspect ratio, if applicable. Framerate and resolution doesn't matter, only if the resolution changes the field of view. Too low shutter speed may also cause undesirable motion blur, but it's usually fine. Record the pattern while slowly moving around to different angles and distances in one clip. 60 seconds is typically more than enough. Try to avoid motion blur by holding the camera still in each angles and with slow movements, and make sure the full chessboard is in view. The following angles are recommended for getting distortion information from the full frame: Chessboard filling whole frame Chessboard seen from distance. Chessboard seen at an angle. Each edge of video frame aligned with edge of chessboard. Corner of chessboard aligned with corner of video. The default (14x8) calibration pattern is also available below:","title":"Getting calibration footage"},{"location":"guide/calibration/#creating-camera-preset","text":"Start the Gyroflow tool and click create new under the lens profile tab. Open the previously recorded calibration video file. Either begin auto calibration or manually add frames using add calibration point from the timeline context menu. After either the automatic or manual calibration process, check the reprojection error . This value describes the overall error between the preset and actual lens distortion based on the expected features of the calibration pattern. After all required frames are added and processed, the straight lines should be straight in the undistorted video. Reprojection error should typically be under 5 (pixels) with excellent calibrations giving values below 1. Fill in the preset information and export the lens profile. Try to add all relevant information about the camera/lens combination including field of view setting and lens focal length if applicable. If a successful calibration was achieved with a low reprojection error and no obvious artefacts, the profile can be submitted with the Upload lens profile to the database checkbox. You're now ready to use the new lens preset. These are stored as .json files.","title":"Creating camera preset"},{"location":"guide/calibration/#additional-calibration-options","text":"The lens calibrator contains additional options.","title":"Additional calibration options"},{"location":"guide/calibration/#default-output-size","text":"Radial lens undistortion typically results in the image being stretched more in the horizontal axis (use the FOV slider to see this). For instance, undistorted 4:3 GoPro video: Notice that the area of the valid rectangle is close to a 16:9 aspect ratio as opposed to 4:3. In these cases, the default output size can be modified to a 16:9 one. For cameras with minimal fisheye distortion, or even with pincushion distortion, the resulting valid aspect ratio is close to the original one. For these cameras, just use the input resolution for the default output size.","title":"Default output size"},{"location":"guide/calibration/#sharpness-limit","text":"Sets the minimum required sharpness for the calibration pattern. If the pattern failed to detect due to focus or blurriness, try increasing this limit.","title":"Sharpness limit"},{"location":"guide/installation/","text":"Minimum system requirements: Windows 10 64-bit (1809 or later) macOS 10.14 or later (both Intel and Apple Silicon are supported natively) Linux: .tar.gz package (recommended): Debian 10+, Ubuntu 18.10+, CentOS 8.2+, openSUSE 15.3+. Other distros require glibc 2.28+ ( ldd --version to check) .AppImage should work everywhere Make sure you have latest graphics drivers installed Possibly needed packages: sudo apt install libva2 libvdpau1 libasound2 libxkbcommon0 libpulse0 libc++-dev vdpau-va-driver libvulkan1 GPU specific packages: NVIDIA: nvidia-opencl-icd nvidia-vdpau-driver nvidia-egl-icd nvidia-vulkan-icd libnvcuvid1 libnvidia-encode1 Intel: intel-media-va-driver i965-va-driver beignet-opencl-icd intel-opencl-icd AMD: mesa-vdpau-drivers mesa-va-drivers mesa-opencl-icd libegl-mesa0 mesa-vulkan-drivers Android 6+ Releases Prebuilt executables are available for Windows, Mac, and Linux. These can be found on the releases page Build local version For development purposes, a local version can be built. For instructions, see the README on GitHub :","title":"Installation"},{"location":"guide/installation/#minimum-system-requirements","text":"Windows 10 64-bit (1809 or later) macOS 10.14 or later (both Intel and Apple Silicon are supported natively) Linux: .tar.gz package (recommended): Debian 10+, Ubuntu 18.10+, CentOS 8.2+, openSUSE 15.3+. Other distros require glibc 2.28+ ( ldd --version to check) .AppImage should work everywhere Make sure you have latest graphics drivers installed Possibly needed packages: sudo apt install libva2 libvdpau1 libasound2 libxkbcommon0 libpulse0 libc++-dev vdpau-va-driver libvulkan1 GPU specific packages: NVIDIA: nvidia-opencl-icd nvidia-vdpau-driver nvidia-egl-icd nvidia-vulkan-icd libnvcuvid1 libnvidia-encode1 Intel: intel-media-va-driver i965-va-driver beignet-opencl-icd intel-opencl-icd AMD: mesa-vdpau-drivers mesa-va-drivers mesa-opencl-icd libegl-mesa0 mesa-vulkan-drivers Android 6+","title":"Minimum system requirements:"},{"location":"guide/installation/#releases","text":"Prebuilt executables are available for Windows, Mac, and Linux. These can be found on the releases page","title":"Releases"},{"location":"guide/installation/#build-local-version","text":"For development purposes, a local version can be built. For instructions, see the README on GitHub :","title":"Build local version"},{"location":"guide/quickstart/","text":"Quick start guide for Gyroflow 1.0.0 Download the executable corresponding to your system: https://github.com/gyroflow/gyroflow/releases Run the executable. Either open or drag your video file to Gyroflow. Lens profile and motion data files are automatically detected for some cameras (GoPros). Otherwise search for the correct lens profile and open the motion data file. Playback video to check if additional synchronization is required. If so, right-click on the timeline and select Auto sync here at at least two points of the video where some motion is present. This synchronises the gyro data and the video. Play with the stabilization options and algorithms. They all give different \"looks\" for the final result. Select output file settings and export.","title":"Quick start guide"},{"location":"guide/quickstart/#quick-start-guide-for-gyroflow-100","text":"Download the executable corresponding to your system: https://github.com/gyroflow/gyroflow/releases Run the executable. Either open or drag your video file to Gyroflow. Lens profile and motion data files are automatically detected for some cameras (GoPros). Otherwise search for the correct lens profile and open the motion data file. Playback video to check if additional synchronization is required. If so, right-click on the timeline and select Auto sync here at at least two points of the video where some motion is present. This synchronises the gyro data and the video. Play with the stabilization options and algorithms. They all give different \"looks\" for the final result. Select output file settings and export.","title":"Quick start guide for Gyroflow 1.0.0"},{"location":"guide/settings/","text":"Gyroflow has a large number of settings for customizing everything. This page contains a short description and guide to each of the settings. Luckily, many of the settings are self-explanatory. Figure: Full screenshot Input/video information After opening a video file, video information and metadata are displayed here. Frame rate Set this value to the actual recording frame rate if it doesn't match the detected frame rate. This is the case for footage from some high speed cameras which play back in slow motion. Rotation Modify the angle if unexpected video rotation is present (e.g. camera accidentally recording using portrait mode). Lens profile Gyroflow requires correct lens profiles for undistortion and correctly applying the stabilization. For GoPro cameras, this is automatically detected based on the metadata. For other cameras, either search for the lens profile, or create a new profile (see the calibration guide ). The lens profile is specific to a combination of a camera, a lens, a field of view, and the recording setting/aspect ratio. In general, it is best if the profile matches the setup exactly, but the same profile can be used if everything else matches except: Frame rate Resolution (with the same FOV and aspect ratio) This is the case since the lens distortion is independent from the framerate and is scaled to account for resolution differences. Lens profiles are stored as JSON files, which can be loaded without being part of the database. Motion data The motion data can either be embedded in the video file (GoPro/Insta360/Sony) or loaded as a separate motion data file (drone blackbox/Runcam/etc). Videos with embedded motion data can be treated as a motion data file as well, meaning an action camera like a GoPro can be mounted on a larger camera as a motion logger. The log detection and parsing uses telemetry-parser For more information about specific gyro logging methods, see pages under Gyro Logging . Low pass filter Gyro data (especially from drones) can be noisy without filtering. Low pass filters essentially reduce frequencies above the cutoff frequency. If the gyro data appears too noisy, try enabling this filter with a cutoff of 50 Hz, with lower frequencies giving more filtering ( more info here ). Rotation If the gyroscope sensor isn't aligned at right angles with the camera, an additional rotation can be applied here. For FPV users using blackbox data with a camera tilt, change the Pitch value to match the angle between the camera and the flight controller. IMU Orientation The compact xyz notation is used to describe the right-angle orientation between the camera and the gyro, with uppercase letters being positive and lowercase being negative. In most cases, this is automatically detected, but if stabilization appears to be applied in the wrong direction/axis, changing the IMU orientation may be required. Integration method For translating the raw gyroscope and accelerometer sensor readings to actual orientations usable for video stabilization, an integration method is used. Currently available are: None - Only applicable for cameras with pre-computed orientations (Hero 8 and newer) Madgwick filter Complementary filter Mahony filter Gyroflow integration Madgwick, Complementary, and Mahony all use a combination of gyroscope and accelerometer for estimating the orientation. The accelerometer allows for determining the downwards direction, meaning these integrators can be used with Lock horizon . With horizon lock, the Complementary filter usually gives decent results with the least horizon drift, but you can compare yourself. By comparison, the Gyroflow option only uses the gyroscope and doesn't work with horizon leveling. For hero 8 and newer, selecting None means no synchronization is required at all. Synchronization Synchronization is typically required between the video and and gyro data. This can either be auto-sync, or by manually syncing at specified times by right-clicking the timeline. Rough gyro offset If a significant delay is present between the start of the video recording and gyro recording, the rough gyro offset needs to be changed. Example: if you start video recording followed by gyro recording 30 seconds later, use 30 s here. Sync search size Gyroflow analyzes a segment of the video, and attempts to find the most likely match within this search size in order to avoid false positives. Max sync points Number of automatically added sync points. Analyze every n-th frame This is typically left unchanged. By setting this to a number larger than 1, frames are skipped during the motion analysis. One use case is high framerate footage, where the relative motion between two subsequent frames is too small for reliable sync. Time to analyze per sync point Determines the number of frames analyzed analyzed for each sync point. More frames take slightly longer, but may give a better sync. The default is typically fine. Optical flow method Select the optical flow implementation. Either OpenCV (typically faster and preferred) or AKAZE. Offset calculation method This is the method used to estimate the gyro-video offset. Using essential matrix - Estimate relative roll/pitch/yaw angular rates between each frame, and correlate with gyro sensor data. Using visual features - Estimate the gyro offset such that the tracked features move the least between frames. Low pass filter Apply a low pass filter to the estimated video motion. This is rarely needed. Show detected features / Show optical flow Shows the motion in the video player during playback Stabilization This is an exciting menu: The actual video stabilization! In general, try playing with the different stabilization algorithms. Each result in a different \"look\" for the stabilized video. If you're interested in developing your own stabilization algorithm, take a look here . FOV Apply a scale to the field of view of the output video. Stabilization algorithm The currently available stabilization algorithms are: No smoothing - Useful if only lens undistortion is desired Plain 3D - Simple general purpose smoothing algorithm described here . Smoothing applied symmetrically in 3D with no rotation limit (doesn't work for rapid camera motion). Velocity dampened - Decreases the smoothing during significant camera motion in order to avoid the image moving out of frame. Velocity dampened per axis - Similar to Velocity dampened with individual roll/pitch/yaw smoothness control. Typically the roll axis can be smoothed out more. Lock horizon - Attempts to keep the horizon level. Works best for flight without fast rotational moves since some gyros can be maxed out. Try with the complementary filter. Fixed camera - Points the virtual camera in a fixed, used-defined direction. Can be useful for debugging or tweaking sync. Crop Select the behavior of the cropping. No cropping - Remain at the user-defined FOV throughout the video Dynamic cropping - Dynamically adjust the field of view in order to hide any borders throughout the video. The Smoothing window influences how quickly the FOV changes in response to different stabilized frame orientations. Static crop - Static crop with FOV=1 being the FOV at which no edges are visible throughout the video. Rolling shutter correction Rolling shutter artifacts are visible during fast camera motion, and appears as \"wobbling\" or skewed lines. This option requires precise gyro-video sync. Find a spot in the video with clear rolling shutter artifacts, and adjust the frame readout time until these artifacts are minimized. By default, the frame readout is assumed to be from top to bottom. This is changed with the checkbox. The readout time can also be estimated with the \"Estimate rolling shutter here\" option in the context menu of the timeline, although this is experimental. Export The options here are fairly self-explanatory. For any doubts, see the tooltips. By default, the resolution and bitrate are selected to correspond closely to the input file From the dropdown of the export button, it is possible to export a .gyroflow . This file contains all the required data and sync information for a video file, and is automatically detected the next time you want to process the same file.","title":"Settings"},{"location":"guide/settings/#inputvideo-information","text":"After opening a video file, video information and metadata are displayed here.","title":"Input/video information"},{"location":"guide/settings/#frame-rate","text":"Set this value to the actual recording frame rate if it doesn't match the detected frame rate. This is the case for footage from some high speed cameras which play back in slow motion.","title":"Frame rate"},{"location":"guide/settings/#rotation","text":"Modify the angle if unexpected video rotation is present (e.g. camera accidentally recording using portrait mode).","title":"Rotation"},{"location":"guide/settings/#lens-profile","text":"Gyroflow requires correct lens profiles for undistortion and correctly applying the stabilization. For GoPro cameras, this is automatically detected based on the metadata. For other cameras, either search for the lens profile, or create a new profile (see the calibration guide ). The lens profile is specific to a combination of a camera, a lens, a field of view, and the recording setting/aspect ratio. In general, it is best if the profile matches the setup exactly, but the same profile can be used if everything else matches except: Frame rate Resolution (with the same FOV and aspect ratio) This is the case since the lens distortion is independent from the framerate and is scaled to account for resolution differences. Lens profiles are stored as JSON files, which can be loaded without being part of the database.","title":"Lens profile"},{"location":"guide/settings/#motion-data","text":"The motion data can either be embedded in the video file (GoPro/Insta360/Sony) or loaded as a separate motion data file (drone blackbox/Runcam/etc). Videos with embedded motion data can be treated as a motion data file as well, meaning an action camera like a GoPro can be mounted on a larger camera as a motion logger. The log detection and parsing uses telemetry-parser For more information about specific gyro logging methods, see pages under Gyro Logging .","title":"Motion data"},{"location":"guide/settings/#low-pass-filter","text":"Gyro data (especially from drones) can be noisy without filtering. Low pass filters essentially reduce frequencies above the cutoff frequency. If the gyro data appears too noisy, try enabling this filter with a cutoff of 50 Hz, with lower frequencies giving more filtering ( more info here ).","title":"Low pass filter"},{"location":"guide/settings/#rotation_1","text":"If the gyroscope sensor isn't aligned at right angles with the camera, an additional rotation can be applied here. For FPV users using blackbox data with a camera tilt, change the Pitch value to match the angle between the camera and the flight controller.","title":"Rotation"},{"location":"guide/settings/#imu-orientation","text":"The compact xyz notation is used to describe the right-angle orientation between the camera and the gyro, with uppercase letters being positive and lowercase being negative. In most cases, this is automatically detected, but if stabilization appears to be applied in the wrong direction/axis, changing the IMU orientation may be required.","title":"IMU Orientation"},{"location":"guide/settings/#integration-method","text":"For translating the raw gyroscope and accelerometer sensor readings to actual orientations usable for video stabilization, an integration method is used. Currently available are: None - Only applicable for cameras with pre-computed orientations (Hero 8 and newer) Madgwick filter Complementary filter Mahony filter Gyroflow integration Madgwick, Complementary, and Mahony all use a combination of gyroscope and accelerometer for estimating the orientation. The accelerometer allows for determining the downwards direction, meaning these integrators can be used with Lock horizon . With horizon lock, the Complementary filter usually gives decent results with the least horizon drift, but you can compare yourself. By comparison, the Gyroflow option only uses the gyroscope and doesn't work with horizon leveling. For hero 8 and newer, selecting None means no synchronization is required at all.","title":"Integration method"},{"location":"guide/settings/#synchronization","text":"Synchronization is typically required between the video and and gyro data. This can either be auto-sync, or by manually syncing at specified times by right-clicking the timeline.","title":"Synchronization"},{"location":"guide/settings/#rough-gyro-offset","text":"If a significant delay is present between the start of the video recording and gyro recording, the rough gyro offset needs to be changed. Example: if you start video recording followed by gyro recording 30 seconds later, use 30 s here.","title":"Rough gyro offset"},{"location":"guide/settings/#sync-search-size","text":"Gyroflow analyzes a segment of the video, and attempts to find the most likely match within this search size in order to avoid false positives.","title":"Sync search size"},{"location":"guide/settings/#max-sync-points","text":"Number of automatically added sync points.","title":"Max sync points"},{"location":"guide/settings/#analyze-every-n-th-frame","text":"This is typically left unchanged. By setting this to a number larger than 1, frames are skipped during the motion analysis. One use case is high framerate footage, where the relative motion between two subsequent frames is too small for reliable sync.","title":"Analyze every n-th frame"},{"location":"guide/settings/#time-to-analyze-per-sync-point","text":"Determines the number of frames analyzed analyzed for each sync point. More frames take slightly longer, but may give a better sync. The default is typically fine.","title":"Time to analyze per sync point"},{"location":"guide/settings/#optical-flow-method","text":"Select the optical flow implementation. Either OpenCV (typically faster and preferred) or AKAZE.","title":"Optical flow method"},{"location":"guide/settings/#offset-calculation-method","text":"This is the method used to estimate the gyro-video offset. Using essential matrix - Estimate relative roll/pitch/yaw angular rates between each frame, and correlate with gyro sensor data. Using visual features - Estimate the gyro offset such that the tracked features move the least between frames.","title":"Offset calculation method"},{"location":"guide/settings/#low-pass-filter_1","text":"Apply a low pass filter to the estimated video motion. This is rarely needed.","title":"Low pass filter"},{"location":"guide/settings/#show-detected-features-show-optical-flow","text":"Shows the motion in the video player during playback","title":"Show detected features / Show optical flow"},{"location":"guide/settings/#stabilization","text":"This is an exciting menu: The actual video stabilization! In general, try playing with the different stabilization algorithms. Each result in a different \"look\" for the stabilized video. If you're interested in developing your own stabilization algorithm, take a look here .","title":"Stabilization"},{"location":"guide/settings/#fov","text":"Apply a scale to the field of view of the output video.","title":"FOV"},{"location":"guide/settings/#stabilization-algorithm","text":"The currently available stabilization algorithms are: No smoothing - Useful if only lens undistortion is desired Plain 3D - Simple general purpose smoothing algorithm described here . Smoothing applied symmetrically in 3D with no rotation limit (doesn't work for rapid camera motion). Velocity dampened - Decreases the smoothing during significant camera motion in order to avoid the image moving out of frame. Velocity dampened per axis - Similar to Velocity dampened with individual roll/pitch/yaw smoothness control. Typically the roll axis can be smoothed out more. Lock horizon - Attempts to keep the horizon level. Works best for flight without fast rotational moves since some gyros can be maxed out. Try with the complementary filter. Fixed camera - Points the virtual camera in a fixed, used-defined direction. Can be useful for debugging or tweaking sync.","title":"Stabilization algorithm"},{"location":"guide/settings/#crop","text":"Select the behavior of the cropping. No cropping - Remain at the user-defined FOV throughout the video Dynamic cropping - Dynamically adjust the field of view in order to hide any borders throughout the video. The Smoothing window influences how quickly the FOV changes in response to different stabilized frame orientations. Static crop - Static crop with FOV=1 being the FOV at which no edges are visible throughout the video.","title":"Crop"},{"location":"guide/settings/#rolling-shutter-correction","text":"Rolling shutter artifacts are visible during fast camera motion, and appears as \"wobbling\" or skewed lines. This option requires precise gyro-video sync. Find a spot in the video with clear rolling shutter artifacts, and adjust the frame readout time until these artifacts are minimized. By default, the frame readout is assumed to be from top to bottom. This is changed with the checkbox. The readout time can also be estimated with the \"Estimate rolling shutter here\" option in the context menu of the timeline, although this is experimental.","title":"Rolling shutter correction"},{"location":"guide/settings/#export","text":"The options here are fairly self-explanatory. For any doubts, see the tooltips. By default, the resolution and bitrate are selected to correspond closely to the input file From the dropdown of the export button, it is possible to export a .gyroflow . This file contains all the required data and sync information for a video file, and is automatically detected the next time you want to process the same file.","title":"Export"},{"location":"guide/synchronization/","text":"This page describes the gyro-video synchronization process in more detail. In a lot of cases, automatic sync works out of the box, so this is only required for tricky scenarios.","title":"Synchronization"},{"location":"integrations/OpenFX/","text":"The Gyroflow OpenFX plugin allows for applying a .gyroflow file to a video directly in the video editor. This plugin is under development by Ilya Epifanov . Downloads and instructions can be found on the GitHub Repository: gyroflow-ofx","title":"OpenFX Plugin"},{"location":"logging/actioncamlogger/","text":"Due to the flexibility of Gyroflow, the gyro source and the video source can be \"mismatched\". This means that an action camera with internal gyro logging (e.g. GoPro) can be mounted to a high-end cinema camera acting as a gyro logger. This setup is illustrated below. The advantages of this setup is the availability of GoPros/Insta360 cameras among filmmakers, meaning no additional hardware other than some fasteners. With this setup, a number of things should be considered: The cinema camera and logger camera should be rigidly attached to each other to avoid mismatching motion data. The two should ideally be oriented in the same direction to avoid additional angle corrections. Starting recording of the two cameras at almost the same time, or with a small fixed offset (e.g. 10 seconds) makes synchronization easier. This setup has successfully been used with GoPro Hero 6/8/9, the Insta360 OneR/Go 2 among others. In general, any camera with gyro logging should work, assuming the gyro data is clean and correct. When using a GoPro hero 8 or newer as a gyro logger, the internally computed orientations ( None integration method) should not be used, since these orientations only correspond to each frame from the GoPro file.","title":"Action cam as logger"},{"location":"logging/betaflight/","text":"Betaflight/Cleanflight/Inav/Emuflight/etc form a popular family of flight control firmware for high-performance multicopters. By using the built-in blackbox logging feature, gyro data for use with Gyroflow video stabilization can be collected. This was in fact one of the initial goals of the project! Betaflight, Cleanflight, Inav, Emuflight etc. all use more or less the same structure for handling blackbox data logging, so this page covers all of these. Hardware As you may already know, the above mentioned flight firmwares can all run on the same type of hardware. A flight controller supporting this family of flight firmwares typically contain: STMicroelectronics 32 bit microcontroller (F4, F7, H7) MEMS inertial measurement unit (MPU6000, BHI160, ICM2xxxx, ICM4xxxx etc.) Some flight controllers have an onboard magnetometer. In general, this is not required for video stabilization purposes unless absolute orientation is desired. Different gyros exhibit different behaviors in terms of data quality, noise, etc. In general, if the IMU is capable of providing clean data for the drone control loop, the same data is suitable for video stabilization purposes. For blackbox data logging, the hardware typically either contains an onboard SPI Flash chip, or a slot for an SD card. If neither of these are available, additional hardware solutions can be connected to the flight controller in order to enable blackbox logging. This can be using: The Openlager - A open source and commercially available board containing an STM32f4 and a MicroSD slot for logging high rate data through a spare serial port. Tiny Blackbox - An open source ultra-light logger containing a 16 MB flash chip. SparkFun OpenLog - A serial-based logger similar to the Openlager. This is no longer officially supported by Betaflight etc. due to data rate limitations. Betaflight/(Cleanflight/Emuflight?) Required software: Betaflight/Cleanflight/Emuflight configurator Betaflight blackbox explorer The following should be a decent starting point for the blackbox configuration 500 Hz logging rate Debug mode: None If you're running Betaflight 4.3 or newer, it is possible to deselect specific elements of the data logging in order to save precious recording space. From the CLI: set blackbox_disable_pids = ON set blackbox_disable_rc = ON set blackbox_disable_setpoint = ON set blackbox_disable_bat = ON set blackbox_disable_mag = ON set blackbox_disable_alt = ON set blackbox_disable_rssi = ON set blackbox_disable_debug = ON set blackbox_disable_motors = ON set blackbox_disable_gps = ON Betaflight configurator blackbox tab","title":"Betaflight/INav/Cleanflight/etc."},{"location":"logging/betaflight/#hardware","text":"As you may already know, the above mentioned flight firmwares can all run on the same type of hardware. A flight controller supporting this family of flight firmwares typically contain: STMicroelectronics 32 bit microcontroller (F4, F7, H7) MEMS inertial measurement unit (MPU6000, BHI160, ICM2xxxx, ICM4xxxx etc.) Some flight controllers have an onboard magnetometer. In general, this is not required for video stabilization purposes unless absolute orientation is desired. Different gyros exhibit different behaviors in terms of data quality, noise, etc. In general, if the IMU is capable of providing clean data for the drone control loop, the same data is suitable for video stabilization purposes. For blackbox data logging, the hardware typically either contains an onboard SPI Flash chip, or a slot for an SD card. If neither of these are available, additional hardware solutions can be connected to the flight controller in order to enable blackbox logging. This can be using: The Openlager - A open source and commercially available board containing an STM32f4 and a MicroSD slot for logging high rate data through a spare serial port. Tiny Blackbox - An open source ultra-light logger containing a 16 MB flash chip. SparkFun OpenLog - A serial-based logger similar to the Openlager. This is no longer officially supported by Betaflight etc. due to data rate limitations.","title":"Hardware"},{"location":"logging/betaflight/#betaflightcleanflightemuflight","text":"Required software: Betaflight/Cleanflight/Emuflight configurator Betaflight blackbox explorer The following should be a decent starting point for the blackbox configuration 500 Hz logging rate Debug mode: None If you're running Betaflight 4.3 or newer, it is possible to deselect specific elements of the data logging in order to save precious recording space. From the CLI: set blackbox_disable_pids = ON set blackbox_disable_rc = ON set blackbox_disable_setpoint = ON set blackbox_disable_bat = ON set blackbox_disable_mag = ON set blackbox_disable_alt = ON set blackbox_disable_rssi = ON set blackbox_disable_debug = ON set blackbox_disable_motors = ON set blackbox_disable_gps = ON Betaflight configurator blackbox tab","title":"Betaflight/(Cleanflight/Emuflight?)"},{"location":"logging/customlogger/","text":"This page contains an example of how data logging can be implemented. Hardware An MEMS Inertial Measurement Unit (MEMS IMU) is a chip containing a gyroscope and an accelerometer. The gyroscope measures the rotational rate, while the accelerometer measures acceleration as the name implies. Gyroflow requires the gyroscope, while the accelerometer is optional and only required if horizon referencing is desired. An example of the acceleration and rotational axes around a camera is illustrated above. Many camera systems already contain such an IMU for electronic image stabilization, so in some cases, it is possible to allow for motion logging through a firmware update. For a dedicated logger, a simple combination of a memory device (MicroSD/SPI Flash chip etc.), a microcontroller, and an inertial measurement unit suffices. This hardware combination is readily available as low-cost drone flight controllers, which can act as loggers as described on another page . Dedicated hardware for this task is currently under development as part of the Gyroflow project. Software/Firmware On the software and firmware side, the inertial measurement unit should be configured correctly. Refer to the datasheet of your IMU for information about how to configure this exactly. It has been found that the following IMU settings offer a reasonable starting point. logging rate: 500 Hz Low pass filter cutoff: 100 Hz gyro scaling: 1000 deg/s acceleration scaling: +/- 4 g The minimum logging rate sufficient for stabilization is approximately 100 Hz, but note that such a low logging rate requires excellent filtering in order to avoid data loss and aliasing. Using a 500 Hz logging rate with a 100 Hz cutoff allows for some margin of error in terms of aliasing. Logging Logging of Gyroscope, and optionally, Accelerometer and Magnetometer can be in various formats. The .gcsv log format described here is a simple to implement format suitable for basic motion loggers.","title":"Custom hardware/logger"},{"location":"logging/customlogger/#hardware","text":"An MEMS Inertial Measurement Unit (MEMS IMU) is a chip containing a gyroscope and an accelerometer. The gyroscope measures the rotational rate, while the accelerometer measures acceleration as the name implies. Gyroflow requires the gyroscope, while the accelerometer is optional and only required if horizon referencing is desired. An example of the acceleration and rotational axes around a camera is illustrated above. Many camera systems already contain such an IMU for electronic image stabilization, so in some cases, it is possible to allow for motion logging through a firmware update. For a dedicated logger, a simple combination of a memory device (MicroSD/SPI Flash chip etc.), a microcontroller, and an inertial measurement unit suffices. This hardware combination is readily available as low-cost drone flight controllers, which can act as loggers as described on another page . Dedicated hardware for this task is currently under development as part of the Gyroflow project.","title":"Hardware"},{"location":"logging/customlogger/#softwarefirmware","text":"On the software and firmware side, the inertial measurement unit should be configured correctly. Refer to the datasheet of your IMU for information about how to configure this exactly. It has been found that the following IMU settings offer a reasonable starting point. logging rate: 500 Hz Low pass filter cutoff: 100 Hz gyro scaling: 1000 deg/s acceleration scaling: +/- 4 g The minimum logging rate sufficient for stabilization is approximately 100 Hz, but note that such a low logging rate requires excellent filtering in order to avoid data loss and aliasing. Using a 500 Hz logging rate with a 100 Hz cutoff allows for some margin of error in terms of aliasing.","title":"Software/Firmware"},{"location":"logging/customlogger/#logging","text":"Logging of Gyroscope, and optionally, Accelerometer and Magnetometer can be in various formats. The .gcsv log format described here is a simple to implement format suitable for basic motion loggers.","title":"Logging"},{"location":"logging/flowbox/","text":"Flowbox is an extremely compact gyro logger developed for use with Gyroflow. It is not yet available, but you can find info about it here","title":"Flowbox"},{"location":"logging/gcsv/","text":".gcsv gyro log format Warning What follows is a text-based gyro log format that can easily be implemented in custom hardware/firmware called .gcsv (short for gyro csv or gyroflow csv). Firstly, for a video file called videofilename.mp4 , the corresponding gyro log file is videofilename.gcsv . This allows for automatic log detection. The .gcsv file contains information about the gyro orientation, scaling, and a unique identifier. For a logger supporting logging of gyro and accelerometer: GYROFLOW IMU LOG version,1.1 id,custom_logger_name orientation,XYZ note,development_test fwversion,FIRMWARE_0.1.0 timestamp,1644159993 vendor,potatocam videofilename,videofilename.mp4 lensprofile,potatocam_mark1_prime_7_5mm_4k tscale,0.001 gscale,0.00122173047 ascale,0.00048828125 t,gx,gy,gz,ax,ay,az 0,39,86,183,-1137,-15689,-2986 1,56,100,202,-1179,-15694,-2887 2,63,108,218,-1247,-15702,-2794 3,71,108,243,-1308,-15675,-2727 4,83,101,268,-1420,-15662,-2661 5,101,93,294,-1575,-15661,-2629 6,121,95,319,-1677,-15654,-2639 7,143,97,348,-1709,-15673,-2654 8,163,98,362,-1704,-15691,-2685 9,173,93,371,-1678,-15698,-2736 10,181,98,375,-1623,-15697,-2810 11,173,105,365,-1578,-15693,-2929 12,159,111,363,-1555,-15711,-3057 13,157,113,348,-1540,-15747,-3159 14,157,118,327,-1542,-15780,-3246 15,153,123,310,-1595,-15812,-3319 Breaking this down: The first line identifies the file as a IMU log. This line should either be GYROFLOW IMU LOG or the more neutral CAMERA IMU LOG . The second line version,1.1 describes the \"version\" of the .gcsv file format. This is equal to 1.1 for now. The third line contains a unique ID associated with the logger/camera. For instance a high-end camera with internal logging may use id,potatocam_deluxe_4k_grey_edition . The forth line contains the orientation string. This corresponds to the IMU Orientation field in Gyroflow. The next few lines with note , fwversion , timestamp , vendor , videofilename , lenspreset are all optional. Note is for other misc. information, fwversion is the firmware of the logger/camera, timestamp is the unix timestamp when logging began, vendor can contain the vendor or developer, videofilename is the name of the corresponding video file, lensprofile is the unique name of the lens preset. The subsequent lines with tscale , ascale and gscale describe constants used to scale the raw sensor values. Multiplying tscale by the raw t values should give the time in seconds . It can thus be deduced that the file above is logging at 1000 Hz. Multiplying ascale by the raw ax/ay/az values should give the acceleration in g Multiplying gscale by the raw gx/gy/gz values should give the angular rate in rad/s The rest of the file simply consists of a standard CSV header and the raw values. Note that fixed-point integers are used with a scalar in order to avoid excessively large text files. Using floating points here is still valid though. The required parts of the header of the .gcsv file remains static for a given camera/setup, and can thus be written as a constant string to the file. Raw sensor values are often represented as 16-bit signed integers, meaning a range between of +/- 2^15 . If the acceleration range is known to be +/- 4 g as was the case in the example above. Then ascale = 4/2^15 = 0.00012207031 . Refer to the datasheet for conversion information. Similarly, a gyroscope with a range of +/- 1000 deg/s gives gscale = (1000 * pi / 180)/2^15 = 0.00053263221 . Note that even when configured to a setting such as +/- 1000 deg/s , the actual calibration of the sensor may lead to maximum slightly above or below this value. As always, consult the datasheet. If a magnetometer is present, it's simply: GYROFLOW IMU LOG version,1 id,custom_logger_name orientation,YxZ tscale,0.001 gscale,0.0002663161 ascale,0.00059875488 mscale,0.00059875488 t,gx,gy,gz,ax,ay,az,mx,my,mz 0,39,86,183,-1137,-15689,-2986,123,345,546 1,56,100,202,-1179,-15694,-2887,124,344,560 with mscale leading to values in gauss (Note that 1 tesla = 10000 gauss ). Similarly, if only gyroscope data is used, the ax,ay,az columns can be left out. For a logger/camera implementation, some other things to think about: For a camera, the timestamps should be based on the same time source as the video capture. This prevents drift between the two. Consider using microseconds for the timestamp if a faster sampling rate if the time source allows. This may improve the timing during the sync process. Consider using the data ready interrupts of IMU's instead of polling for more consistent timings. For the IMU Orientation string, the following figure corresponds to YxZ :","title":"Gyroflow .gcsv reference"},{"location":"logging/gcsv/#gcsv-gyro-log-format","text":"Warning What follows is a text-based gyro log format that can easily be implemented in custom hardware/firmware called .gcsv (short for gyro csv or gyroflow csv). Firstly, for a video file called videofilename.mp4 , the corresponding gyro log file is videofilename.gcsv . This allows for automatic log detection. The .gcsv file contains information about the gyro orientation, scaling, and a unique identifier. For a logger supporting logging of gyro and accelerometer: GYROFLOW IMU LOG version,1.1 id,custom_logger_name orientation,XYZ note,development_test fwversion,FIRMWARE_0.1.0 timestamp,1644159993 vendor,potatocam videofilename,videofilename.mp4 lensprofile,potatocam_mark1_prime_7_5mm_4k tscale,0.001 gscale,0.00122173047 ascale,0.00048828125 t,gx,gy,gz,ax,ay,az 0,39,86,183,-1137,-15689,-2986 1,56,100,202,-1179,-15694,-2887 2,63,108,218,-1247,-15702,-2794 3,71,108,243,-1308,-15675,-2727 4,83,101,268,-1420,-15662,-2661 5,101,93,294,-1575,-15661,-2629 6,121,95,319,-1677,-15654,-2639 7,143,97,348,-1709,-15673,-2654 8,163,98,362,-1704,-15691,-2685 9,173,93,371,-1678,-15698,-2736 10,181,98,375,-1623,-15697,-2810 11,173,105,365,-1578,-15693,-2929 12,159,111,363,-1555,-15711,-3057 13,157,113,348,-1540,-15747,-3159 14,157,118,327,-1542,-15780,-3246 15,153,123,310,-1595,-15812,-3319 Breaking this down: The first line identifies the file as a IMU log. This line should either be GYROFLOW IMU LOG or the more neutral CAMERA IMU LOG . The second line version,1.1 describes the \"version\" of the .gcsv file format. This is equal to 1.1 for now. The third line contains a unique ID associated with the logger/camera. For instance a high-end camera with internal logging may use id,potatocam_deluxe_4k_grey_edition . The forth line contains the orientation string. This corresponds to the IMU Orientation field in Gyroflow. The next few lines with note , fwversion , timestamp , vendor , videofilename , lenspreset are all optional. Note is for other misc. information, fwversion is the firmware of the logger/camera, timestamp is the unix timestamp when logging began, vendor can contain the vendor or developer, videofilename is the name of the corresponding video file, lensprofile is the unique name of the lens preset. The subsequent lines with tscale , ascale and gscale describe constants used to scale the raw sensor values. Multiplying tscale by the raw t values should give the time in seconds . It can thus be deduced that the file above is logging at 1000 Hz. Multiplying ascale by the raw ax/ay/az values should give the acceleration in g Multiplying gscale by the raw gx/gy/gz values should give the angular rate in rad/s The rest of the file simply consists of a standard CSV header and the raw values. Note that fixed-point integers are used with a scalar in order to avoid excessively large text files. Using floating points here is still valid though. The required parts of the header of the .gcsv file remains static for a given camera/setup, and can thus be written as a constant string to the file. Raw sensor values are often represented as 16-bit signed integers, meaning a range between of +/- 2^15 . If the acceleration range is known to be +/- 4 g as was the case in the example above. Then ascale = 4/2^15 = 0.00012207031 . Refer to the datasheet for conversion information. Similarly, a gyroscope with a range of +/- 1000 deg/s gives gscale = (1000 * pi / 180)/2^15 = 0.00053263221 . Note that even when configured to a setting such as +/- 1000 deg/s , the actual calibration of the sensor may lead to maximum slightly above or below this value. As always, consult the datasheet. If a magnetometer is present, it's simply: GYROFLOW IMU LOG version,1 id,custom_logger_name orientation,YxZ tscale,0.001 gscale,0.0002663161 ascale,0.00059875488 mscale,0.00059875488 t,gx,gy,gz,ax,ay,az,mx,my,mz 0,39,86,183,-1137,-15689,-2986,123,345,546 1,56,100,202,-1179,-15694,-2887,124,344,560 with mscale leading to values in gauss (Note that 1 tesla = 10000 gauss ). Similarly, if only gyroscope data is used, the ax,ay,az columns can be left out. For a logger/camera implementation, some other things to think about: For a camera, the timestamps should be based on the same time source as the video capture. This prevents drift between the two. Consider using microseconds for the timestamp if a faster sampling rate if the time source allows. This may improve the timing during the sync process. Consider using the data ready interrupts of IMU's instead of polling for more consistent timings. For the IMU Orientation string, the following figure corresponds to YxZ :","title":".gcsv gyro log format"},{"location":"logging/general/","text":"Gyroflow needs a source of Gyro data (and optionally accelerometer data) to operate. Currently, Gyroflow supports the following gyro log types: Supported gyro sources [x] GoPro (HERO 5 and later) [x] Sony (a1, a6600, a7c, a7r IV, a7 IV, a7s III, a9 II, FX3, FX6, RX0 II, RX100 VII, ZV1, ZV-E10) [x] Insta360 (OneR, SMO 4k, GO2) [x] Betaflight blackbox (CSV and binary) [x] Mobile apps: Sensor Logger , G-Field Recorder , Gyro [x] Runcam CSV (Runcam 5 Orange, iFlight GOCam GR) [x] WitMotion (WT901SDCL binary and *.txt) The subsequent pages will contain information about specific logging methods.","title":"General"},{"location":"logging/general/#supported-gyro-sources","text":"[x] GoPro (HERO 5 and later) [x] Sony (a1, a6600, a7c, a7r IV, a7 IV, a7s III, a9 II, FX3, FX6, RX0 II, RX100 VII, ZV1, ZV-E10) [x] Insta360 (OneR, SMO 4k, GO2) [x] Betaflight blackbox (CSV and binary) [x] Mobile apps: Sensor Logger , G-Field Recorder , Gyro [x] Runcam CSV (Runcam 5 Orange, iFlight GOCam GR) [x] WitMotion (WT901SDCL binary and *.txt) The subsequent pages will contain information about specific logging methods.","title":"Supported gyro sources"},{"location":"tech/filtering/","text":"For video stabilization, logging rates of at least 100 Hz of clean data has shown to work, with clean being the keyword. This page contains some info about the quality of the gyro data. Aliasing For number one, adequate filtering should be applied before the saving step in order to satisfy the Nyquist\u2013Shannon sampling theorem . This may sound fancy, but just means the frequencies in the signal should be limited to at most, half the sampling frequency. For a 200 Hz logging rate, a low pass/decimation filter with a cutoff of about 100 Hz should be applied. Most MEMS gyroscopes contain on-board options for low pass filtering, but depending on the exact chip, this may not be adequate for handling harsh vibration-heavy environments on a drone. Gyro-camera coupling The physical gyro should match the motion of the camera, meaning no or minimal play should be present between the two. This is not a problem for builtin gyro logging. Filtering If no aliasing is present, the gyro data can be further filtered, assuming the sampling rate is sufficiently high. Roughly speaking, the frequencies of camera shake lie below 50 Hz. Frequencies above this could either be noise or high frequency signals resulting from high frequency, but low amplitude vibrations.","title":"Filtering and noise"},{"location":"tech/filtering/#aliasing","text":"For number one, adequate filtering should be applied before the saving step in order to satisfy the Nyquist\u2013Shannon sampling theorem . This may sound fancy, but just means the frequencies in the signal should be limited to at most, half the sampling frequency. For a 200 Hz logging rate, a low pass/decimation filter with a cutoff of about 100 Hz should be applied. Most MEMS gyroscopes contain on-board options for low pass filtering, but depending on the exact chip, this may not be adequate for handling harsh vibration-heavy environments on a drone.","title":"Aliasing"},{"location":"tech/filtering/#gyro-camera-coupling","text":"The physical gyro should match the motion of the camera, meaning no or minimal play should be present between the two. This is not a problem for builtin gyro logging.","title":"Gyro-camera coupling"},{"location":"tech/filtering/#filtering","text":"If no aliasing is present, the gyro data can be further filtered, assuming the sampling rate is sufficiently high. Roughly speaking, the frequencies of camera shake lie below 50 Hz. Frequencies above this could either be noise or high frequency signals resulting from high frequency, but low amplitude vibrations.","title":"Filtering"},{"location":"tech/relatedprojects/","text":"This page contains projects and technical literature which may be of interest to those wanting to learn more about gyro-based video stabilization. Gyro-assisted video stabilization projects Legacy Python-version of Gyroflow Virtual Gimbal by Yoshiaki Sato. Another gyro-assisted stabilization tool Video-Stabilization by Alex Karpenko. One of the first implementations of the method Papers Digital Video Stabilization and Rolling Shutter Correction using Gyroscopes - 2011 paper describing gyro-assisted video stabilization Animating Rotation with Quaternion Curves - Describes SLERP, used for orientation smoothing in Gyroflow A Generic Camera Model and Calibration Method for Conventional, Wide-Angle, and Fish-Eye Lenses - the default lens model used in Gyroflow Online Gyroscope-Camera Autocalibration for Image Enhancement on Smartphones - Master Thesis about gyro-assisted video stabilization","title":"Related Projects/Literature"},{"location":"tech/relatedprojects/#gyro-assisted-video-stabilization-projects","text":"Legacy Python-version of Gyroflow Virtual Gimbal by Yoshiaki Sato. Another gyro-assisted stabilization tool Video-Stabilization by Alex Karpenko. One of the first implementations of the method","title":"Gyro-assisted video stabilization projects"},{"location":"tech/relatedprojects/#papers","text":"Digital Video Stabilization and Rolling Shutter Correction using Gyroscopes - 2011 paper describing gyro-assisted video stabilization Animating Rotation with Quaternion Curves - Describes SLERP, used for orientation smoothing in Gyroflow A Generic Camera Model and Calibration Method for Conventional, Wide-Angle, and Fish-Eye Lenses - the default lens model used in Gyroflow Online Gyroscope-Camera Autocalibration for Image Enhancement on Smartphones - Master Thesis about gyro-assisted video stabilization","title":"Papers"},{"location":"tech/rollingshutter/","text":"Rolling shutter artifacts are caused by camera sensors reading lines sequentially instead of simultaneously (global shutter). With the correct settings, Gyroflow is capable of correcting for rolling shutter artifacts. Frame readout time determination There are multiple ways of determining the frame readout time. One approach is by recording a rapidly flashing source of light with a known frequency or pulse width, and analyzing the resulting image. For a known pulse width, the size of the bands can be used in order to find the frame readout time. For a known frequency, the number of bands can be counted. Using LED's for rolling shutter measurements is described in this blog post: https://joancharmant.com/blog/measuring-rolling-shutter-with-a-strobing-led/","title":"Rolling Shutter"},{"location":"tech/rollingshutter/#frame-readout-time-determination","text":"There are multiple ways of determining the frame readout time. One approach is by recording a rapidly flashing source of light with a known frequency or pulse width, and analyzing the resulting image. For a known pulse width, the size of the bands can be used in order to find the frame readout time. For a known frequency, the number of bands can be counted. Using LED's for rolling shutter measurements is described in this blog post: https://joancharmant.com/blog/measuring-rolling-shutter-with-a-strobing-led/","title":"Frame readout time determination"},{"location":"tech/smoothing/","text":"In order to stabilize the orientation, a smoothing algorithm is used. This is in essence a low pass filter applied to the 3D orientation. To illustrate how this works, let's take one of the simplest low pass filters in 1D: the exponential filter , also known as exponential moving average or exponentially weighted moving average depending on the field of study (see the wikipedia article for more info). If \\(\\alpha\\) be a number between 0 and 1 and the \\(Y_t\\) being the t-th input sample. The output, \\(S_t\\) of this low pass filter is then: \\[ {\\displaystyle S_{t}={\\begin{cases}Y_{1},&t=0\\\\\\alpha Y_{t}+(1-\\alpha )\\cdot S_{t-1},&t>0\\end{cases}}} \\] This can be seen as a weighted average between the previous output and the newest input sample. Alternatively this can be seen as the output moving a fractional amount towards to input for each sample. The result is a smoothed 1D signal, but introduces a delay in the signal. By applying the same filter twice in opposite directions, this delay is eliminated. Now, how can this be expanded to 3D? A three-dimensional orientation needs to be represented by at least there numbers, so one obvious way of filtering the orientation is to apply the low pass filter to each axis. Although this works, the result might not be the smoothing you expect. For instance, if the orientation is represented by an Euler angle, applying a low pass filter to each axis leads to non-linear behavior in the resulting orientation. If instead the orientations are represented by quaternions, the Slerp (Spherical Linear Interpolation, wiki article ) method invented by Ken Shoemake can be used. Slerp can compute the intermediate orientation (quaternion) between two original quaternions corresponding to a smooth trajectory between the two. This is exactly what's needed for the simple exponential smoothing, since the weighted sum is equivalent to starting at \\(Y_{t}\\) and moving a fractional distance of \\(\\alpha\\) towards \\(S_{t-1}\\) . This filter can thus be translated to an orientation filter as follows: \\[ {\\displaystyle q_{out,t}={\\begin{cases}q_{in,t},&t=0\\\\Slerp(q_{in,t}, q_{out,t-1},\\alpha) ,&t>0\\end{cases}}} \\] Once again, this is applied in both directions to counteract the introduced delay. The difference between the input quaternions (estimated camera motion) and output quaternions (smoothed virtual camera) is then used for the image stabilization process. Due to the simplicity, this orientation filter was the first one implemented in the Gyroflow project, but has a number of limitations, mainly during large camera shakes and the lack of smoothness control for each rotational axis. Nevertheless, you should now have an overview of how the general smoothing algorithm works (Input orientation quaternions -> Smoothing algo -> Smoothed orientation quaternions) which might give you ideas for your own smoothing algorithm.","title":"Orientations and smoothing"}]}